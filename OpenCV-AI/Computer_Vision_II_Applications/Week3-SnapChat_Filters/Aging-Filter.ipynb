{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# <font style = \"color:rgb(50,120,229)\">SnapChat Filters : Aging<\/font>\n",
                "\n",
                "# <font style = \"color:rgb(50,120,229)\">Introduction<\/font>\n",
                "\n",
                "Back in 2012, three apps were released on the Apple App Store - Fatify, Baldify and Oldify. While the results looked decent and the apps were great for fun and giggles, I wondered who would buy the app. Turns out millions of people did and the apps made millions of dollars! \n",
                "\n",
                "In this lecture, we will learn how to apply an aging filter to a face. Based on what we have learned so far, you have all the knowledge needed to write an aging filter. \n",
                "\n",
                "> <font style=\"font-family:Poiret one\" size = \"+2\">So, I want you to pause for 15 minutes and write down how you would go about building an aging filter.<\/font> \n",
                "\n",
                "## <font style = \"color:rgb(50,120,229)\">The Core Idea<\/font>\n",
                "\n",
                "Before we design a filter, let\u2019s first think of the various ways age affects the appearance of the face.\n",
                "\n",
                "<center><a href=\"https:\/\/www.learnopencv.com\/wp-content\/uploads\/2018\/01\/opcv4face-w5-m5-agingImage.png\"><img src=\"https:\/\/www.learnopencv.com\/wp-content\/uploads\/2018\/01\/opcv4face-w5-m5-agingImage.png\" width=500\/><\/a><\/center>\n",
                "\n",
                "1. **Wrinkles:** The most prominent change is perhaps the appearance of wrinkles on the face. \n",
                "\n",
                "2. **Spots:** It is very common for brown and black spots to show up on parts of the skin that is exposed to the sun. These spots are called Liver spots even though they have nothing to do with the Liver. \n",
                "\n",
                "3. **Paler appearance:** The skin actually appears pale and translucent. \n",
                "\n",
                "4. **Lower elasticity:** The skin loses elasticity and sags. \n",
                "\n",
                "If we think like a scientist, we will try to reproduce each of these effects on a facial photo. But this is a course for engineers. We will use shortcuts whenever we can! \n",
                "\n",
                "A frontal facial photograph of an old person, shown above, exhibits a lot of features related to aging. Can we borrow those features and apply it to our image? Yes, and that is the core idea. \n",
                "\n",
                "First, we will warp the wrinkle image to the coordinates of the input images and then perform seamless cloning with MIXED_CLONE option. \n",
                "\n",
                "We will go over the steps in the code section. However, there are a few things worth discussing before we dive into the code. \n",
                "\n",
                "### <font style = \"color:rgb(50,120,229)\">How to Estimate Forehead Points<\/font>\n",
                "\n",
                "We know that Dlib\u2019s landmark detector does not produce any points on the forehead. For aging application it is very important to have some points on the forehead because forehead wrinkles are important for showing aging. \n",
                "\n",
                "There are a few different ways of estimating forehead points. \n",
                "\n",
                "1. Train a new landmark detector with points on the forehead. \n",
                "\n",
                "2. Estimate the forehead points based on the current landmark points.\n",
                "\n",
                "Of the two above two methods, the first one is no doubt more elegant, but it requires a large data collection effort. If you were building a commercial application, this may be the right path to take. \n",
                "<center><a href=\"https:\/\/www.learnopencv.com\/wp-content\/uploads\/2018\/01\/opcv4face-w5-m5-landmarkPoints.png\"><img src=\"https:\/\/www.learnopencv.com\/wp-content\/uploads\/2018\/01\/opcv4face-w5-m5-landmarkPoints.png\" width=400\/><\/a><\/center>\n",
                "There are a few different ways of using option 2. One can train a linear regressor, that takes as input the current landmark points and outputs the forehead points. To train the linear regressor we need to manually mark forehead landmarks on a few hundred images. \n",
                "\n",
                "The final option is to come up with a heuristic that works fine for the application. We guesstimate four forehead points. See figure on the left. \n",
                "\n",
                "For each one of them we pick a point on the lower eyelid and another point on the eyebrow and extend the line by a fixed amount to land at our estimate of the forehead point. \n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### <font style = \"color:rgb(50,120,229)\">How to Generate a Mask from Points<\/font>\n",
                "\n",
                "Given a set of points on a polygon, we know we can create a mask using fillPoly or fillConvexPoly in OpenCV. \n",
                "\n",
                "Facial landmarks do not form a polygon. To find a face mask, we need to find a Convex Hull of all points. \n",
                "\n",
                "### <font style = \"color:rgb(50,120,229)\">What is a Convex hull?<\/font>\n",
                "<center><a href=\"https:\/\/www.learnopencv.com\/wp-content\/uploads\/2018\/01\/opcv4face-w5-m5-convexHull.png\"><img src=\"https:\/\/www.learnopencv.com\/wp-content\/uploads\/2018\/01\/opcv4face-w5-m5-convexHull.png\" width=400\/><\/a><\/center>\n",
                "\n",
                "&nbsp;\n",
                "The image on the left shows a few red points. The blue line is the Convex Hull. The convex hull of has two important properties\n",
                "\n",
                "1. It is a **convex polygon.** This means that all internal angles are less than 180 degrees. The outer boundary has no concavities. \n",
                "\n",
                "2. It is a **hull**. The word hull is used in many contexts and almost everywhere it refers to the outer covering of something. In this case, the hull refers to the outer boundary of the points. All the points are either inside or on the hull. \n",
                "\n",
                "In OpenCV, you can use the function `convexHull` to find the convexHull.\n",
                "\n",
                "In the code below, we use the convex hull to find a mask for the face to perform seamless cloning."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### <font style = \"color:rgb(8,133,37)\">Aging Filter Code and Tutorial<\/font>\n",
                "\n",
                "Sometimes, it is easy to assume we know something but the devil is in the code! Let\u2019s dive in and explore. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 101,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys, cv2, dlib, time\n",
                "import numpy as np\n",
                "import faceBlendCommon as fbc\n",
                "import matplotlib.pyplot as plt\n",
                "from dataPath import DATA_PATH\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 102,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib\n",
                "matplotlib.rcParams['figure.figsize'] = (6.0,6.0)\n",
                "matplotlib.rcParams['image.cmap'] = 'gray'\n",
                "matplotlib.rcParams['image.interpolation'] = 'bilinear'"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "First, let's write some functions for alpha blending, image desaturation, etc."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 103,
            "metadata": {},
            "outputs": [],
            "source": [
                "def alphaBlend(alpha, foreground, background):\n",
                "  fore = np.zeros(foreground.shape, dtype=foreground.dtype)\n",
                "  fore = cv2.multiply(alpha, foreground, fore, 1\/255.0)\n",
                "\n",
                "  alphaPrime = np.ones(alpha.shape, dtype=alpha.dtype)*255 - alpha\n",
                "  back = np.zeros(background.shape, dtype=background.dtype)\n",
                "  back = cv2.multiply(alphaPrime, background, back, 1\/255.0)\n",
                "\n",
                "  outImage = cv2.add(fore, back)\n",
                "  return outImage"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 123,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Desaturate image\n",
                "def desaturateImage(im, scaleBy):\n",
                "\n",
                "  # Convert input image to HSV\n",
                "  imgHSV = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n",
                "\n",
                "  # Multiple saturation by the scale\n",
                "  imgHSV[:, :, 1] = imgHSV[:, :, 1]*scaleBy\n",
                "\n",
                "  # Convert HSV to RGB\n",
                "  outImage = cv2.cvtColor(imgHSV, cv2.COLOR_HSV2BGR)\n",
                "\n",
                "  return outImage"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 124,
            "metadata": {},
            "outputs": [],
            "source": [
                "def removePolygonFromMask(mask, points, pointsIndex):\n",
                "  hullPoints = []\n",
                "  for pIndex in pointsIndex:\n",
                "    hullPoints.append(points[pIndex])\n",
                "\n",
                "  cv2.fillConvexPoly(mask, np.int32(hullPoints), (0, 0, 0))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 125,
            "metadata": {},
            "outputs": [],
            "source": [
                "def appendForeheadPoints(points):\n",
                "  offsetScalp = 3.0\n",
                "  brows = [25, 23, 20, 18]\n",
                "  browsReference = [45, 47, 40, 36]\n",
                "\n",
                "  for browPoint, browRefPoint in zip(brows, browsReference):\n",
                "    foreheadPointX = int(offsetScalp * (points[browPoint][0] - points[browRefPoint][0]) + points[browRefPoint][0])\n",
                "    foreheadPointY = int(offsetScalp * (points[browPoint][1] - points[browRefPoint][1]) + points[browRefPoint][1])\n",
                "    points.append((foreheadPointX, foreheadPointY))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 126,
            "metadata": {},
            "outputs": [],
            "source": [
                "def getFaceMask(size, points):\n",
                "  # Left eye polygon\n",
                "  leftEye = [36, 37, 38, 39, 40, 41]\n",
                "  # Right eye polygon\n",
                "  rightEye = [42, 43, 44, 45, 46, 47]\n",
                "  # Mouth polygon\n",
                "  mouth = [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
                "  # Nose polygon\n",
                "  nose = [28, 31, 33, 35]\n",
                "\n",
                "  # Find Convex hull of all points\n",
                "  hullIndex = cv2.convexHull(np.array(points), returnPoints=False)\n",
                "\n",
                "  # Convert hull index to list of points\n",
                "  hullInt = []\n",
                "  for hIndex in hullIndex:\n",
                "    hullInt.append(points[hIndex[0]])\n",
                "\n",
                "  # Create mask such that convex hull is white\n",
                "  mask = np.zeros((size[0], size[1], 3), dtype=np.uint8)\n",
                "  cv2.fillConvexPoly(mask, np.int32(hullInt), (255, 255, 255))\n",
                "\n",
                "  # Remove eyes, mouth and nose from the mask\n",
                "  removePolygonFromMask(mask, points, leftEye)\n",
                "  removePolygonFromMask(mask, points, rightEye)\n",
                "  removePolygonFromMask(mask, points, nose)\n",
                "  removePolygonFromMask(mask, points, mouth)\n",
                "\n",
                "  return mask"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Load face detector and facial landmark detector"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 127,
            "metadata": {},
            "outputs": [],
            "source": [
                "modelPath = DATA_PATH + \"models\/shape_predictor_68_face_landmarks.dat\"\n",
                "\n",
                "# initialize face detector\n",
                "faceDetector = dlib.get_frontal_face_detector()\n",
                "# initialize facial landmark detector\n",
                "landmarkDetector = dlib.shape_predictor(modelPath)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Read wrinkle image (`img1`) and input image (`img2`). The wrinkles will be applied to the input image."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 128,
            "metadata": {},
            "outputs": [],
            "source": [
                "# File to copy wrinkles from\n",
                "filename1 = DATA_PATH + \"images\/wrinkle2.jpg\"\n",
                "\n",
                "# File to apply aging\n",
                "filename2 = DATA_PATH + \"images\/ted_cruz.jpg\"\n",
                "\n",
                "t = time.time()\n",
                "\n",
                "# Read images\n",
                "img1 = cv2.imread(filename1)\n",
                "img2 = cv2.imread(filename2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 129,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(20,20))\n",
                "\n",
                "plt.subplot(121)\n",
                "plt.imshow(img1[:,:,::-1])\n",
                "plt.title(\"Wrinkle Image (img1)\")\n",
                "ax = plt.axis('off')\n",
                "\n",
                "plt.subplot(122)\n",
                "plt.imshow(img2[:,:,::-1])\n",
                "plt.title(\"Input Image (img2)\")\n",
                "ax = plt.axis('off')\n",
                "\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Find landmarks and guesstimate forehead points "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 130,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find landmarks\n",
                "points1 = fbc.getLandmarks(faceDetector, landmarkDetector, img1)\n",
                "points2 = fbc.getLandmarks(faceDetector, landmarkDetector, img2)\n",
                "\n",
                "# Find forehead points\n",
                "appendForeheadPoints(points1)\n",
                "appendForeheadPoints(points2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 131,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find Delaunay Triangulation\n",
                "sizeImg1 = img1.shape\n",
                "rect = (0, 0, sizeImg1[1], sizeImg1[0])\n",
                "dt = fbc.calculateDelaunayTriangles(rect, points1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Warp the wrinkle image to the input image one triangle at a time. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 132,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert image for warping\n",
                "img1 = np.float32(img1)\/255.0\n",
                "img2 = np.float32(img2)\/255.0\n",
                "\n",
                "# Warp wrinkle image to face image\n",
                "img1Warped = np.copy(img2)\n",
                "img1Warped = fbc.warpImage(img1, img1Warped, points1, points2, dt, useOutputImageSize=True)\n",
                "img1Warped = np.uint8(img1Warped*255.0)\n",
                "img2 = np.uint8(img2*255.0)\n",
                "\n",
                "plt.imshow(img1Warped[:,:,::-1])\n",
                "ax = plt.axis('off')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We do not want parts of the input image to be affected by the wrinkle image. So we create a mask where the eyes, mouth and nose regions are masked out.\n",
                "\n",
                "The variable `clonedOutput` stores the results after seamless cloning. Noted we are using the `MIXED_CLONE` option because we just want the high gradient regions (wrinkles \/ spots etc.) from the wrinkle image."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 133,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate face mask for seamless cloning\n",
                "mask = getFaceMask(img2.shape[0:2], points2)\n",
                "\n",
                "# Seamlessly clone the wrinkle image onto original face\n",
                "r1 = cv2.boundingRect(np.float32(points2))\n",
                "# Bounding rectangle r1 has 4 elements: left(x1), top(y1), \n",
                "# width(w), height(h)\n",
                "center1X = r1[0] + int(r1[2]\/2.0)\n",
                "center1Y = r1[1] + int(r1[3]\/2.0)\n",
                "center1 = (center1X, center1Y)\n",
                "clonedOutput = cv2.seamlessClone(img1Warped, img2, \n",
                "                               mask, center1, \n",
                "                               cv2.MIXED_CLONE)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 134,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(20,20))\n",
                "plt.subplot(131)\n",
                "plt.imshow(mask)\n",
                "ax = plt.axis('off')\n",
                "\n",
                "\n",
                "plt.subplot(132)\n",
                "plt.imshow(img1Warped[:,:,::-1])\n",
                "ax = plt.axis('off')\n",
                "\n",
                "\n",
                "plt.subplot(133)\n",
                "plt.imshow(clonedOutput[:,:,::-1])\n",
                "ax = plt.axis('off')\n",
                "\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "When with seamless cloning, it is a good idea to blur the mask and use it to alpha blend the original image. This is because the mask is made out of polygons with sharp edges and these edges may show up in the final image.\n",
                "\n",
                "The mask can be of any size. To apply a consistent blur, we can resize the mask to a constant size, apply a constant size blur on it, and then resize it back to the original size. Admittedly, this is a hack. One can argue that the right way is to apply a large blur kernel to the high resolution image. But doing so can be computationally expensive. Hence, this computationally cheap hack.\n",
                "\n",
                "Also, notice we erode the mask slightly before blurring it. This is because we want the alpha to be near zero near the boundary of the seamless cloned region because the boundary has a sharp edge."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 135,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Blurring face mask to alpha blend to hide seams\n",
                "maskHeight, maskWidth = mask.shape[0:2]\n",
                "maskSmall = cv2.resize(mask, (256, int(maskHeight*256.0\/maskWidth)))\n",
                "maskSmall = cv2.erode(maskSmall, (-1, -1), 25)\n",
                "maskSmall = cv2.GaussianBlur(maskSmall, (51, 51), 0, 0)\n",
                "mask = cv2.resize(maskSmall, (maskWidth, maskHeight))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Once the mask is blurred, we alpha blend the original image and the cloned image.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 136,
            "metadata": {},
            "outputs": [],
            "source": [
                "agedImage = alphaBlend(mask, clonedOutput, img2)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The blurred mask, cloned image and the alpha blended images are shown below. Note the sharp edge visible on the forehead in `clonedOutput` is much better blended in `agedImage`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 137,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(20,20))\n",
                "\n",
                "plt.subplot(131)\n",
                "plt.imshow(mask)\n",
                "plt.title(\"Blurred Mask\")\n",
                "ax = plt.axis('off')\n",
                "\n",
                "plt.subplot(132)\n",
                "plt.imshow(clonedOutput[:,:,::-1])\n",
                "plt.title(\"Cloned Output\")\n",
                "ax = plt.axis('off')\n",
                "\n",
                "plt.subplot(133)\n",
                "plt.imshow(agedImage[:,:,::-1])\n",
                "plt.title(\"Cloned Output (Soft Mask)\")\n",
                "ax = plt.axis('off')\n",
                "\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Finally, we desaturate the final image. It has two effects. First, aging leads to a paler skin and desaturation simulates that effect. Second, the entire photo looks discolored and old. The overall effect is that we make the person look old and from an old time."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 144,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Desaturate output\n",
                "output = desaturateImage(agedImage, 0.8)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 145,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display results\n",
                "plt.figure(figsize=(20,20))\n",
                "\n",
                "plt.subplot(121)\n",
                "plt.imshow(img2[:,:,::-1])\n",
                "plt.title(\"Original Image\")\n",
                "plt.axis('off')\n",
                "\n",
                "plt.subplot(122)\n",
                "plt.imshow(output[:,:,::-1])\n",
                "plt.title(\"Aged Image\")\n",
                "ax = plt.axis('off')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text\/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}