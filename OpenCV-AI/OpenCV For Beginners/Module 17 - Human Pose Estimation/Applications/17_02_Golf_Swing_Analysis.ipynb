{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71dc4fee",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\">Application: Golf Swing Analysis and Training</h1> \n",
    "\n",
    "Sports training and instruction are heavily based on video analysis to better inform students of proper form for various activities such as throwing, kicking, and swinging. Instructors often use videos of professionals to help instruct their students, but visual comparison can be tedious, often requiring the use of a mouse to manually annotate video frames at various stages to show key differences.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "<img src = \"https://opencv.org/wp-content/uploads/2021/10/c0-m17-02-Feature-Image.png\" alt=\"Golf-swing-analysis\">\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "In this application notebook we will demonstrate how to use landmark points from MediaPipe Pose to develop a visual application that allows you to compare a student's golf swing to a reference golf swing from a professional. Video frames are automatically annotated with important geometric relationships that help inform the student in a more efficient manner. \n",
    "\n",
    "Designing a proper sports training aid requires domain expertise for the given sport. This notebook provides the basis for such an application applied to the golf swing. The body of information for any given sport for proper technique is deep and even subjective in some cases, but there is no doubt that professionals in any given sport collectively demonstrate certain fundamentals which can be visually quantified and compared to the form of the student's execution. This particular application allows you to visually compare golf swings at key moments during the swing to determine where the student's form can be improved by comparing their video frames to a reference video from a professional golfer.\n",
    "\n",
    "Reference golf swing from: [GolfswingHD](https://www.youtube.com/watch?v=wIiLM8ufWVI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02608282",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    print(\"Downloading Code to Colab Environment\")\n",
    "    !wget https://www.dropbox.com/sh/gz8x999ela84qr2/AABHRkHY_QALmo6JHSpOruA8a?dl=1 -O module-code.zip -q --show-progress\n",
    "    !unzip -qq module-code.zip\n",
    "    !pip install --upgrade opencv-contrib-python\n",
    "    !pip install mediapipe\n",
    "    %cd Applications/\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fb0b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0b4afd",
   "metadata": {},
   "source": [
    "# 1. Preview Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd87a0c",
   "metadata": {},
   "source": [
    "## 1.1 Student Golf Swing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c4c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = VideoFileClip('./Student_Swing_DTL_wide.mp4')\n",
    "clip.ipython_display(width=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97660ef5",
   "metadata": {},
   "source": [
    "## 1.2 Reference Golf Swing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382418bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference video from GolfswingHD: https://www.youtube.com/watch?v=wIiLM8ufWVI\n",
    "clip = VideoFileClip('./Reference_Swing_DTL.mp4')\n",
    "clip.ipython_display(width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28718aa2",
   "metadata": {},
   "source": [
    "# 2. Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83916e5d",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50,120,230)\">Create video capture object<font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5aa3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name  = 'Reference_Swing_DTL.mp4'\n",
    "video_cap = cv2.VideoCapture(file_name)\n",
    "if not video_cap.isOpened():\n",
    "    print('Unable to open: ' + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674b30c4",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50,120,230)\">Create video writer object<font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c37934",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_w = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_h = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_size = (frame_w, frame_h)\n",
    "\n",
    "video_out_file = file_name[:-4] + '_out_landmarks.mp4'\n",
    "video_output = cv2.VideoWriter(video_out_file, cv2.VideoWriter_fourcc(*'mp4v'), fps, frame_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a4f124",
   "metadata": {},
   "source": [
    "# 3. Extract Landmark Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bd310c",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50,120,230)\">Process image frames and extract landmark coordinates<font/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41acab6",
   "metadata": {},
   "source": [
    "Documentation [**MediaPipe Pose**](https://google.github.io/mediapipe/solutions/pose.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b1e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BGR Colors\n",
    "color_light  = (255, 255, 0)\n",
    "color_marks  = (0, 255, 255)\n",
    "color_join   = (0, 20, 200)\n",
    "\n",
    "# In a more advanced application the initial position of \n",
    "# the golf ball would be automatically detected.\n",
    "ball_pos_x = 650\n",
    "ball_pos_y = 927\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "   \n",
    "    while True:\n",
    "        \n",
    "        has_frame, frame = video_cap.read()\n",
    "        if not has_frame:\n",
    "            break\n",
    "            \n",
    "        # Convert the BGR image to RGB.\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the image frame.\n",
    "        keypoints = pose.process(frame)\n",
    "        landmarks = keypoints.pose_landmarks\n",
    "        enum_pose  = mp_pose.PoseLandmark\n",
    "        \n",
    "        # Convert the image back to BGR.\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        if landmarks is not None:\n",
    "        \n",
    "            # Right ear.\n",
    "            r_ear_x = int(landmarks.landmark[enum_pose.RIGHT_EAR].x * frame_w)\n",
    "            r_ear_y = int(landmarks.landmark[enum_pose.RIGHT_EAR].y * frame_h)\n",
    "            r_ear_p = np.array([r_ear_x, r_ear_y])\n",
    "\n",
    "            # Right wrist.\n",
    "            r_wrist_x = int(landmarks.landmark[enum_pose.RIGHT_WRIST].x * frame_w)\n",
    "            r_wrist_y = int(landmarks.landmark[enum_pose.RIGHT_WRIST].y * frame_h)\n",
    "            r_wrist_p = np.array([r_wrist_x, r_wrist_y])\n",
    "            \n",
    "            # Right hip.\n",
    "            r_hip_x = int(landmarks.landmark[enum_pose.RIGHT_HIP].x * frame_w)\n",
    "            r_hip_y = int(landmarks.landmark[enum_pose.RIGHT_HIP].y * frame_h)\n",
    "            r_hip_p = np.array([r_hip_x, r_hip_y])\n",
    "\n",
    "            # Join landmarks.\n",
    "            cv2.line(frame, (r_hip_p[0], r_hip_p[1] ), (r_ear_p[0], r_ear_p[1]), color_join, 2, cv2.LINE_AA)\n",
    "            cv2.line(frame, (r_hip_p[0], r_hip_p[1] ), (r_wrist_p[0], r_wrist_p[1]), color_join, 2, cv2.LINE_AA)\n",
    "            cv2.line(frame, (r_ear_p[0], r_ear_p[1]), (r_wrist_p[0], r_wrist_p[1]), color_join, 2, cv2.LINE_AA)\n",
    "            cv2.line(frame, (ball_pos_x, ball_pos_y), (r_wrist_p[0], r_wrist_p[1]), color_light, 2, cv2.LINE_AA)\n",
    "\n",
    "            # Draw landmarks.\n",
    "            cv2.circle(frame, (r_ear_p[0], r_ear_p[1]), 3, color_marks, -1)\n",
    "            cv2.circle(frame, (r_wrist_p[0], r_wrist_p[1]), 3, color_marks, -1)\n",
    "            cv2.circle(frame, (r_hip_p[0], r_hip_p[1] ), 3, color_marks, -1)\n",
    "            cv2.circle(frame, (ball_pos_x, ball_pos_y), 3, color_marks, -1)\n",
    "\n",
    "            video_output.write(frame)\n",
    "            \n",
    "video_cap.release()\n",
    "video_output.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54edbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load output video.\n",
    "clip = VideoFileClip(video_out_file)\n",
    "clip.ipython_display(width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780b870a",
   "metadata": {},
   "source": [
    "# 4.  Defining Vectors Between Landmark Points\n",
    "<br>\n",
    "<center>\n",
    "<img src = \"https://opencv.org/wp-content/uploads/2021/10/c0-m17-02-Vectors.png\" alt=\"vectors\">\n",
    "</center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c2d266",
   "metadata": {},
   "source": [
    "# 5. Function to Compute the Angle Between Two Vectors\n",
    "\n",
    "The dot product between two vectors is defined as follows:\n",
    "\n",
    "\\begin{align}\n",
    "{a\\bullet b} = {|a||b|}\\bullet \\cos(\\theta)\n",
    "\\end{align}\n",
    "\n",
    "We can therefore compute the angle between the two vectors re-arranging the above equation.\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\theta = \\arccos (\\frac{a\\bullet b}{|a||b|})\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6119a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_angle(v1, v2):\n",
    "\n",
    "    # Unit vector.\n",
    "    v1u = v1 / np.linalg.norm(v1)\n",
    "    # Unit vector.\n",
    "    v2u = v2 / np.linalg.norm(v2)\n",
    "    # Compute the angle between the two unit vectors.\n",
    "    angle_deg = np.arccos(np.dot(v1u, v2u)) * 180 / math.pi\n",
    "\n",
    "    return angle_deg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2525dfa4",
   "metadata": {},
   "source": [
    "# 5. Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c541809",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50,120,230)\">Create Video Capture Object<font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1368b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_modes = ['reference', 'student', 'student2']\n",
    "\n",
    "mode = run_modes[0]\n",
    "\n",
    "if mode == 'reference':\n",
    "    file_name = 'Reference_Swing_DTL.mp4'\n",
    "elif mode == 'student':\n",
    "    file_name = 'Student_Swing_DTL.mp4'\n",
    "elif mode == 'student2':    \n",
    "    file_name = 'Student_Swing_DTL_wide_impact_2months_later.mp4'\n",
    "\n",
    "video_cap = cv2.VideoCapture(file_name)\n",
    "\n",
    "if not video_cap.isOpened():\n",
    "    print('Unable to open: ' + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4914a314",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50,120,230)\">Create Video Writer Object<font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bca7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_w = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_h = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_size = (frame_w, frame_h)\n",
    "\n",
    "video_out_file = file_name[:-4] + '_out_analysis.mp4'\n",
    "\n",
    "video_output = cv2.VideoWriter(video_out_file, cv2.VideoWriter_fourcc(*'mp4v'), fps, frame_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f905f6ba",
   "metadata": {},
   "source": [
    "# 6. Convenience Function to Extract Landmark Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ce16a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmark_point(landmarks, landmark_point, w, h):\n",
    "    x = int(landmarks.landmark[landmark_point].x * w)\n",
    "    y = int(landmarks.landmark[landmark_point].y * h)\n",
    "    point = np.array([x, y])\n",
    "    return point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2659bd4",
   "metadata": {},
   "source": [
    "# 7. Golf Swing Analysis Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ac8d1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "color_light  = (255, 255, 0)\n",
    "color_marks  = (0, 255, 255)\n",
    "color_yellow = (0, 255, 255)\n",
    "color_gray   = (127, 127, 127)\n",
    "color_join   = (0, 20, 200)\n",
    "\n",
    "first_frame = True\n",
    "\n",
    "# In a more advanced application the initial position of \n",
    "# the golf ball would be automatically detected.\n",
    "if mode == 'reference':\n",
    "    # for: Reference_Swing_DTL.mp4\n",
    "    ball_pos_x = 650\n",
    "    ball_pos_y = 927\n",
    "elif mode == 'student':\n",
    "    # for: Student_Swing_DTL.mp4\n",
    "    ball_pos_x = 640\n",
    "    ball_pos_y = 944\n",
    "elif mode == 'student2':\n",
    "    # for: Student_Swing_DTL_wide_2months_later.mp4\n",
    "    ball_pos_x = 783\n",
    "    ball_pos_y = 613\n",
    "    \n",
    "mp_pose = mp.solutions.pose\n",
    "    \n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        \n",
    "    while True:\n",
    "\n",
    "        has_frame, frame = video_cap.read()\n",
    "        if not has_frame:\n",
    "            break\n",
    "\n",
    "        # Convert the BGR image to RGB.\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the image.\n",
    "        keypoints = pose.process(frame)\n",
    "\n",
    "        # Convert the image back to BGR.\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Use the following assignments to abbreviate the notation further below.\n",
    "        landmarks = keypoints.pose_landmarks\n",
    "        enum_pose = mp_pose.PoseLandmark\n",
    "\n",
    "        if landmarks is not None:\n",
    "            # Acquire the landmark coordinates.\n",
    "            r_ear_p = get_landmark_point(landmarks,   enum_pose.RIGHT_EAR, frame_w, frame_h)\n",
    "            r_wrist_p = get_landmark_point(landmarks, enum_pose.RIGHT_WRIST, frame_w, frame_h)\n",
    "            r_hip_p = get_landmark_point(landmarks,   enum_pose.RIGHT_HIP, frame_w, frame_h)\n",
    "\n",
    "            # Compute angle between ear-hip-wrist.\n",
    "            v_hip_ear = np.subtract(r_ear_p, r_hip_p)\n",
    "            v_hip_wrist = np.subtract(r_wrist_p, r_hip_p)\n",
    "            angle_ear_hip_wrist = compute_angle(v_hip_ear, v_hip_wrist)\n",
    "            text_loc = (r_hip_p[0] - 25, r_hip_p[1] + 20)\n",
    "            cv2.putText(frame, str(int(angle_ear_hip_wrist)), text_loc, cv2.FONT_HERSHEY_SIMPLEX, .5, \n",
    "                        color_light, 1, cv2.LINE_AA)\n",
    "\n",
    "            # Compute angle between ear-hip-vertical.\n",
    "            v_hip_ear = np.subtract(r_ear_p, r_hip_p)\n",
    "            vert_p = np.array([r_hip_p[0], r_hip_p[1] - 1])\n",
    "            v_hip_vert = np.subtract(vert_p, r_hip_p)\n",
    "            angle_ear_hip_vert = compute_angle(v_hip_ear, v_hip_vert)\n",
    "            text_loc = (r_hip_p[0] - 25, r_hip_p[1]  - 10)\n",
    "            cv2.putText(frame, str(int(angle_ear_hip_vert)), text_loc, cv2.FONT_HERSHEY_SIMPLEX, .5, \n",
    "                        color_yellow, 1, cv2.LINE_AA)\n",
    "\n",
    "            # Join landmarks.\n",
    "            cv2.line(frame, (r_hip_p[0], r_hip_p[1] ), (r_ear_p[0], r_ear_p[1]), color_join, 2, cv2.LINE_AA)\n",
    "            cv2.line(frame, (r_hip_p[0], r_hip_p[1] ), (r_wrist_p[0], r_wrist_p[1]), color_join, 2, cv2.LINE_AA)\n",
    "            cv2.line(frame, (r_ear_p[0], r_ear_p[1]), (r_wrist_p[0], r_wrist_p[1]), color_join, 2, cv2.LINE_AA)\n",
    "            cv2.line(frame, (ball_pos_x, ball_pos_y), (r_wrist_p[0], r_wrist_p[1]), color_light, 2, cv2.LINE_AA)\n",
    "\n",
    "            # Draw landmarks.\n",
    "            cv2.circle(frame, (r_ear_p[0], r_ear_p[1]), 3, color_marks, -1)\n",
    "            cv2.circle(frame, (r_wrist_p[0], r_wrist_p[1]), 3, color_marks, -1)\n",
    "            cv2.circle(frame, (r_hip_p[0], r_hip_p[1] ), 3, color_marks, -1)\n",
    "            cv2.circle(frame, (ball_pos_x, ball_pos_y), 3, color_marks, -1)\n",
    "\n",
    "            if first_frame:\n",
    "                r_hip_x_0 = r_hip_p[0]\n",
    "                r_ear_y_0 = r_ear_p[1]\n",
    "                first_frame = False\n",
    "                \n",
    "            # Draw initial vertical and horizontal lines through right hip and right ear.\n",
    "            cv2.line(frame, (r_hip_x_0, frame_h), (r_hip_x_0, 0), color_gray, 1, cv2.LINE_AA)\n",
    "            cv2.line(frame, (0, r_ear_y_0), (frame_w, r_ear_y_0), color_gray, 1, cv2.LINE_AA)\n",
    "\n",
    "            # Draw dynamic vertical and horizontal lines through right hip and right ear.\n",
    "            cv2.line(frame, (r_hip_p[0], frame_h), (r_hip_p[0], 0), color_yellow, 1, cv2.LINE_AA)\n",
    "            cv2.line(frame, (0, r_ear_p[1]), (frame_w, r_ear_p[1]), color_yellow, 1, cv2.LINE_AA)\n",
    "\n",
    "            video_output.write(frame)\n",
    "\n",
    "video_cap.release()\n",
    "video_output.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b5f4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load output video.\n",
    "clip = VideoFileClip(video_out_file)\n",
    "clip.ipython_display(width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460becee",
   "metadata": {},
   "source": [
    "# 8. Analysis of Results\n",
    "\n",
    "The code above was executed twice. Once for the reference swing video and once for the student swing video. In the sections below we will compare two at key points points during the golf swing starting at the address position."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ed4f1e",
   "metadata": {},
   "source": [
    "## 8.1 Comparison at Address\n",
    "\n",
    "The positon of the student at \"address\" is very good. The angle of the spine, and the relative positon of the hands, head, and hips are all in the proper position. Also notice that there is only a slight bending at the knees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de447cff",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src = \"https://opencv.org/wp-content/uploads/2021/10/c0-m17-Golf-Swing-1-Address.png\" alt=\"Golf-swing-1\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e959eca4",
   "metadata": {},
   "source": [
    "## 8.2 Comparison at the Top of the Backswing\n",
    "\n",
    "There are several things to note about the student's form at the top of the backswing. The angle of the spine should be roughly perpendicular to the swing plane (identified in light blue). In this case, the student's spine is too vertical at the top of the backswing which causes him to be out of position. Also, notice that the student's head has shifted vertically up during the backswing (the horizontal yellow line is now substantially higher than it was as address). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa77986a",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src = \"https://opencv.org/wp-content/uploads/2021/10/c0-m17-Golf-Swing-2-Top.png\" alt=\"Golf-swing2-top\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2c9117",
   "metadata": {},
   "source": [
    "## 8.3 Comparison During the Downswing\n",
    "\n",
    "During the downswing, the club shaft should be parallel to the swing plane (light blue line). Notice that the student's club shaft is at a shallower angle than the swing plane. Notice also that the head of the student is still too high compared to the reference swing. Both of these differences could likely be corrected by maintaining a steeper angle of the spine throughout the downswing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf91e737",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src = \"https://opencv.org/wp-content/uploads/2021/10/c0-m17-Golf-Swing-3-Down.png\" alt=\"Golf-Swing-3-Down\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b35f929",
   "metadata": {},
   "source": [
    "## 8.4 Comparison at Impact\n",
    "To his credit, the student's position at impact is remarkably similar to the reference swing in spite of the differences earlier in the swing. The head is lower at impact as it should be. The angle of the spine is in a much better position compared to the reference swing. And the right hip has rotated toward the target line as it should. However, getting to this impact position requires significant timing and is hard to repeat in a consistent manner. Improving the form earlier in the swing will lead to more consistent form throughout the swing which will lead to more consistent contact with the ball. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1cf492",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src = \"https://opencv.org/wp-content/uploads/2021/10/c0-m17-Golf-Swing-4-Impact.png\" alt=\"Golf-swing-4-impact\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d497eda",
   "metadata": {},
   "source": [
    "# 9. Training Improvement (Two Months Later)\n",
    "\n",
    "The following video shows the same student two months later. It's difficult to spot any differences until you see the annotated results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc60f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = VideoFileClip('Student_Swing_DTL_wide_impact_2months_later.mp4')\n",
    "clip.ipython_display(width=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef38409",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = VideoFileClip('./Student_Swing_DTL_wide_impact_2months_later_out_analysis.mp4')\n",
    "clip.ipython_display(width=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eaa38c",
   "metadata": {},
   "source": [
    "# 9.1 Comparison During the Downswing\n",
    "\n",
    "The following comparison below is for the same student two months later. First, looking at the video above notice that the student's spine is still too vertical (26 deg) at the top of the backswing (at 0:09 sec), but there has also been an improvement; his head has remained in the same position that is was at address (yellow vs. gray horizontal lines). There are also three other notable improvements that are apparent during the downswing, with the aid of automated annotations. First, the tilt of the spine (now at 30 deg vs 23 deg) is in a much better position. Second, the head is at a lower position than it was at address. And, third, the angle of the club shaft is slightly steeper (and therefore closer to the ideal swing plane) than it was in the original swing which is mainly due to the steeper angle of the spine at this position in the downswing.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "<img src = \"https://opencv.org/wp-content/uploads/2021/10/c0-m17-Golf-Swing-Improvement.png\" alt=\"Golf-swing-improvement\">\n",
    "</center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca13c730",
   "metadata": {},
   "source": [
    "# Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd717db",
   "metadata": {},
   "source": [
    "As you can see the visual cues from dynamically connecting key landmark points throughout the swing can lead to immediate and informative feedback to instructors and students and can also be used to easily assess progress. Video instruction techniques are commonly used in golf instruction but the geometric relationships are typically drawn manually to identify key differences between a student's swing and a reference swing. Using computer vision techniques, we are able to automate the annotation of video frames in a way that makes instruction much more efficient and effective."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
