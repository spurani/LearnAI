{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Computer Interaction and Introduction to PyAutoGUI\n",
    "This notebook will help you learn about Human-Computer Interaction. You will also learn about PyAutoGUI, a very useful python library that allows us to control computer inputs using python scripts. In this notebook, you will learn the following:\n",
    "\n",
    "* Human-Computer Interaction (HCI)\n",
    "* Applications of HCI\n",
    "* Introduction to PyAutoGUI\n",
    "* Next steps ideas of PyAutoGui and OpenCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human-computer interaction (HCI)\n",
    "\n",
    "**Human-computer interaction (HCI)** focuses on the interfaces between people and computers. Initially concerned with personal computers, HCI now has evolved into a multidisciplinary field, combining practices from a number of fields including:\n",
    "* Computer Science\n",
    "* Psychology\n",
    "* Design\n",
    "* Sociology\n",
    "* Ergonomics \n",
    "\n",
    "and many more.\n",
    "\n",
    "![HCI-features](https://opencv.org/wp-content/uploads/2021/08/c0-m6-hci-features.png)\n",
    "## Examples of HCI\n",
    "\n",
    "From the QWERTY keyboard to VR and AR, everything falls under the umbrella of HCI. Even the voice based assistants such as Siri, Alexa and Google assistant are part of HCI.\n",
    "\n",
    "Google [Project Soli](https://atap.google.com/soli/) is one of many examples where HCI is being taken to new levels and getting immense attention from various industrious including Automation, UX Design, Automobiles, Gaming and even Healthcare.\n",
    "\n",
    "![Soli](https://opencv.org/wp-content/uploads/2021/08/c0-m6-soli-gif.gif)\n",
    "\n",
    "The above is a demonstration of how Google plans to incorporate miniature radar to understand human motions and create gesture based inputs on computing devices like smartphones and smart-watches in the Project Soli. \n",
    "\n",
    "In this notebook, we will learn about **PyAutoGUI** and see how we can use it for creating our own applications of HCI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyAutoGUI\n",
    "\n",
    "*PyAutoGUI* lets our Python scripts control the mouse and keyboard to automate interactions with other applications. It provides a easy way to make fun HCI applications from scratch. It works on Windows, macOS and Linux.\n",
    "\n",
    "**Note:** Most operating systems will require you to grant specific permissions to let your script drive inputs as if coming from your mouse and keyboard.\n",
    "\n",
    "PyAutoGUI has several features:\n",
    "\n",
    "* Moving the mouse and clicking or typing in the windows of other applications.\n",
    "* Sending keystrokes to applications (for example, to fill out forms).\n",
    "* Take screenshots, and given an image (for example, of a button or checkbox), find it on the screen.\n",
    "* Locate an application’s window, and move, resize, maximize, minimize, or close it (Windows-only, currently)\n",
    "* Display message boxes for user interaction while your GUI automation script runs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import PyAutoGUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyautogui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mouse Control Functions\n",
    "\n",
    "<hr style=\"border:none; height: 4px; background-color:#D3D3D3\" />\n",
    "\n",
    "## Screen Size and Mouse Position:\n",
    "\n",
    "Locations on your screen are referred to by X and Y Cartesian coordinates as demonstrated below:\n",
    "```\n",
    "0,0       X increases -->\n",
    "+---------------------------+\n",
    "|                           | Y increases\n",
    "|                           |     |\n",
    "|   1920 x 1080 screen      |     |\n",
    "|                           |     V\n",
    "|                           |\n",
    "|                           |\n",
    "+---------------------------+ 1919, 1079\n",
    "\n",
    "```\n",
    "\n",
    "The screen resolution size is returned by the `size()` function as a tuple of two integers. The current X and Y coordinates of the mouse cursor are returned by the `position()` function.\n",
    "\n",
    "### <font color=\"green\">Function Syntax </font>\n",
    "``` python\n",
    "    size = pyautogui.size()\n",
    "    location = pyautogui.position()\n",
    "```\n",
    "\n",
    "## Mouse Movement\n",
    "\n",
    "The `moveTo()` function will move the mouse cursor to the X and Y integer coordinates you pass it. \n",
    "\n",
    "### <font color=\"green\">Function Syntax </font>\n",
    "``` python\n",
    "    pyautogui.moveTo(X, Y, duration)\n",
    "```\n",
    "\n",
    "1. `X` X coordinate of destination point.\n",
    "2. `Y` Y coordinate of destination point.\n",
    "3. `duration` optional flag  of time (in seconds) the movement should take. \n",
    "\n",
    "If you want to move the mouse cursor over a few pixels relative to its current position, use the `move()` function. This function has similar parameters as `moveTo()`.\n",
    "\n",
    "## Mouse Drag\n",
    "\n",
    "PyAutoGUI’s `dragTo()` and `drag()` functions have similar parameters as the `moveTo()` and `move()` functions. In addition, they have a button keyword which can be set to 'left', 'middle', and 'right' for which mouse button to hold down while dragging.\n",
    "\n",
    "### <font color=\"green\">Function Syntax </font>\n",
    "``` python\n",
    "    pyautogui.dragTo( X, Y, duration, button )\n",
    "```\n",
    "\n",
    "1. `X` X coordinate of destination point.\n",
    "2. `Y` Y coordinate of destination point.\n",
    "3. `duration` optional flag  of time (in seconds) the movement should take.\n",
    "4. `button` button to press while dragging the mouse cursor.\n",
    "\n",
    "## Mouse Clicks\n",
    "\n",
    "The `click()` function simulates a single, left-button mouse click at the mouse’s current position. A “click” is defined as pushing the button down and then releasing it up.\n",
    "### <font color=\"green\">Function Syntax </font>\n",
    "``` python\n",
    "    pyautogui.click(X, Y, button, clicks, interval)\n",
    "```\n",
    "\n",
    "1. `X` optional X coordinate of destination point.\n",
    "2. `Y` optional Y coordinate of destination point.\n",
    "3. `button` button to press while dragging the mouse cursor.\n",
    "4. `clicks` number of clicks to perform\n",
    "5. `interval` specify the amount of pause between the clicks in seconds.\n",
    "\n",
    "### <font color=\"green\">PyAutoGUI Documentation</font>\n",
    "\n",
    "[**Mouse control functions**](https://pyautogui.readthedocs.io/en/latest/mouse.html)\n",
    "\n",
    "<hr style=\"border:none; height: 4px; background-color:#D3D3D3\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of mouse control using PyAutoGUI:\n",
    "\n",
    "Consider a use case where you want to automate the drawing of a specific pattern in a drawing or painting software. While a typical user would click and hold the mouse button to draw a stroke in such an application, it is possible to automate such inputs using the `drag` function. Take a look at the following pattern:\n",
    "\n",
    "![HCI-example](https://opencv.org/wp-content/uploads/2021/08/c0-m6-hci-example.png)\n",
    "\n",
    "The code below can be used to draw this pattern on any graphics drawing program. **Note!** This code does nothing more, and nothing less, than send mouse events to the operating system. It does not need to actually communicate directly with the drawing application. In order for this example to work, the drawing app must already be open and in an appropriate mode (e.g. brush or pencil tool activated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait 2 seconds, to give you time to switch to the drawing application.\n",
    "import time\n",
    "time.sleep(2.0)\n",
    "\n",
    "distance = 200\n",
    "while distance > 0:\n",
    "        pyautogui.drag(distance, 0, button='left', duration=0.5)   # move right\n",
    "        distance -= 50\n",
    "        pyautogui.drag(0, distance, button='left', duration=0.5)   # move down\n",
    "        pyautogui.drag(-distance, 0, button='left', duration=0.5)  # move left\n",
    "        distance -= 50\n",
    "        pyautogui.drag(0, -distance, button='left', duration=0.5)  # move up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyboard Control Functions\n",
    "\n",
    "<hr style=\"border:none; height: 4px; background-color:#D3D3D3\" />\n",
    "\n",
    "## The write() Function\n",
    "\n",
    "The primary keyboard function is `write()`. This function will type the characters in the string that is passed. \n",
    "\n",
    "### <font color=\"green\">Function Syntax </font>\n",
    "``` python\n",
    "    pyautogui.write(string, interval)\n",
    "```\n",
    "1. `string` string to type.\n",
    "2. `interval` to add a delay interval in between pressing each character key.\n",
    "\n",
    "## The press(), keyDown(), and keyUp() Functions\n",
    "\n",
    "To press these keys, call the `press()` function and pass it a string from the `pyautogui.KEYBOARD_KEYS` such as **enter**, **esc**, **f1**. See [KEYBOARD_KEYS](https://pyautogui.readthedocs.io/en/latest/keyboard.html#keyboard-keys).\n",
    "\n",
    "### <font color=\"green\">Function Syntax </font>\n",
    "``` python\n",
    "    pyautogui.press(key, presses, interval)\n",
    "```\n",
    "1. `key` string to denote which button to press.\n",
    "2. `presses` number of key presses.\n",
    "3. `interval` to add a delay interval in between pressing the key\n",
    "\n",
    "The `press()` function is really just a wrapper for the `keyDown()` and `keyUp()` functions.\n",
    "\n",
    "## Hotkeys\n",
    "\n",
    "To make pressing hotkeys or keyboard shortcuts convenient, the `hotkey()` can be passed several key strings which will be pressed down in order, and then released in reverse order.\n",
    "\n",
    "### Example:\n",
    "``` python\n",
    "    pyautogui.hotkey('ctrl', 'shift', 'esc')\n",
    "```\n",
    "To add a delay interval in between each press, pass an int or float for the `interval` keyword argument.\n",
    "Above example is same as: \n",
    "\n",
    "``` python\n",
    "    pyautogui.keyDown('ctrl')\n",
    "    pyautogui.keyDown('shift')\n",
    "    pyautogui.keyDown('esc')\n",
    "    pyautogui.keyUp('esc')\n",
    "    pyautogui.keyUp('shift')\n",
    "    pyautogui.keyUp('ctrl')\n",
    "```\n",
    "\n",
    "### <font color=\"green\">PyAutoGUI Documentation</font>\n",
    "\n",
    "[**Keyboard control functions**](https://pyautogui.readthedocs.io/en/latest/keyboard.html)\n",
    "\n",
    "<hr style=\"border:none; height: 4px; background-color:#D3D3D3\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of keyboard control using PyAutoGUI:\n",
    "\n",
    "Consider the action of opening a new tab in a browser, enter a URL, and then pressing enter to load that page. With the concepts learned above, we can now do that entirely using PyAutoGUI. After pressing run on the cell below, sit back and relax while it opens the PyAutoGUI docs for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Give a moment (half a second) to bring up the application window if needed.\n",
    "time.sleep(0.5)\n",
    "\n",
    "# If on a mac OSX machine, use command key instead of ctrl.\n",
    "hotkey = 'command' if 'mac' in pyautogui.platform.platform() else 'ctrl'\n",
    "\n",
    "# Open a new tab using a shortcut key.\n",
    "pyautogui.hotkey(hotkey, 't')\n",
    "\n",
    "# Give time for the browser to open the tab and be ready for user (typing) input.\n",
    "time.sleep(1.0)\n",
    "\n",
    "# Now type a url at a speedy 100 words per minute!\n",
    "pyautogui.write('https://pyautogui.readthedocs.io', 0.01)\n",
    "\n",
    "# Bring 'focus' to the URL bar (shortcut key may vary depending on your browser).\n",
    "time.sleep(0.1)\n",
    "pyautogui.hotkey(hotkey, 'l')\n",
    "\n",
    "# Press enter to load the page.\n",
    "pyautogui.press('enter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating HCI\n",
    "\n",
    "Now that we are familiar to PyAutoGUI, it is possible to use it for some fun use cases. On its own, you could use it for purely automation use cases like batch filling out PDFs in a PDF editing program.\n",
    "\n",
    "When combined with the power of OpenCV, we can design a whole new way to control your computer using computer vision instead of a mouse and keyboard. There are virtually unlimited possibilities, such as waving a hand around as a means to control the mouse, or using facial expressions to trigger specific actions."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e654b3bc3aace0335b326231d51e90ebd214a7f2d0629a648660f7deb4b3382"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
