# Name the components on this agent
stlog.sources = r1
stlog.sinks = k1
stlog.channels = c1

# Describe/configure the source
stlog.sources.r1.type = exec
stlog.sources.r1.command = tail -F -s 2 /mnt/home/edureka_321047/av/workspace/logs/event2.log

# Describe the sink
stlog.sinks.k1.type = hdfs
stlog.sinks.k1.hdfs.path = use_cases/streaming/events/%Y-%m-%d/
stlog.sinks.k1.hdfs.filePrefix = events-
stlog.sinks.k1.hdfs.fileSuffix = .log
stlog.sinks.k1.hdfs.useLocalTimeStamp = true
stlog.sinks.k1.hdfs.fileType = DataStream

#stlog.sinks.hd.type = hdfs
#stlog.sinks.hd.hdfs.path=tmp/flume_demo/%y-%m-%d
#stlog.sinks.hd.hdfs.writeFormat = Text
#stlog.sinks.hd.hdfs.fileType = DataStream
#stlog.sinks.hd.hdfs.filePrefix = flumedemo
#stlog.sinks.hd.hdfs.useLocalTimeStamp = true
#stlog.sinks.hd.hdfs.path = tmp/kafka/%{topic}/%y-%m-%d
#stlog.sinks.hd.hdfs.rollCount=100
#stlog.sinks.hd.hdfs.rollSize=0

# Use a channel stlogich buffers events in memory
stlog.channels.c1.type = memory
stlog.channels.c1.capacity = 1000
stlog.channels.c1.transactionCapacity = 100

# Bind the source and sink to the channel
stlog.sources.r1.channels = c1
stlog.sinks.k1.channel = c1
