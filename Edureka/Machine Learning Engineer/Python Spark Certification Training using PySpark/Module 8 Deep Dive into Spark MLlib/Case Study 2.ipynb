{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from email.parser import Parser\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "spark = SparkSession.builder.appName(\"Enron\").getOrCreate()\n",
    "rootdir = \"C:\\\\Users\\\\SP.000\\\\Downloads\\\\maildir\\\\blair-l\\\\_sent_mail\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_analyse(inputfile, to_email_list, from_email_list, email_body):\n",
    "    with open(inputfile, \"r\") as f:\n",
    "        data = f.read()\n",
    " \n",
    "    email = Parser().parsestr(data)\n",
    " \n",
    "    if(email['to']):\n",
    "        email_to = email['to']\n",
    "        email_to = email_to.replace('\\n',\"\")\n",
    "        email_to = email_to.replace('\\t',\"\")\n",
    "        email_to = email_to.replace(\" \",\"\")\n",
    "        email_to = email_to.split(\",\")\n",
    "        for email_to_1 in email_to:\n",
    "            to_email_list.append(email_to_1)\n",
    "            email_subject.append((email['subject'],email_to_1,email['from']))\n",
    "    from_email_list.append(email['from'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_email_list = []\n",
    "from_email_list = []\n",
    "email_body = []\n",
    "email_subject = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory, subdirectory, filenames in os.walk(rootdir):\n",
    "    for filename in filenames:\n",
    "        email_analyse(os.path.join(directory,filename), to_email_list, from_email_list, email_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('FYI: Flowers sent to Galen', 'larry.berger@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'raetta.zadow@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'john.buchanan@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'lynn.blair@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'mike.bryant@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'terry.kowalke@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'jean.blair@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'james.carr@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'jodie.floyd@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'katherine.perry@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'shirley.walden@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'nancy.callans@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'kathy.washington@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'diana.porter@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'jerry.wilkens@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'randy.bryan@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'sherry.forbish@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'joe.linhart@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'kathy.sturr@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'chris.greaney@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'janet.mcdaniel@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'robert.benningfield@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'tangie.dykes@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'debra.scurlock@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'randy.janzen@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'jean.adams@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'harry.woodson@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'scott.hibbard@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'beverly.miller@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'albert.hernandez@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'cynthia.rivers@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'linda.ward@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'amy.mulligan@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'tracy.minter@enron.com', 'lynn.blair@enron.com'), ('FYI: Flowers sent to Galen', 'christine.mcevoy@enron.com', 'lynn.blair@enron.com'), ('Terra receivable', 'raetta.zadow@enron.com', 'lynn.blair@enron.com'), ('Terra receivable', 'larry.berger@enron.com', 'lynn.blair@enron.com'), ('FW: Mt. Jesus Condensate', 'harry.woodson@enron.com', 'lynn.blair@enron.com'), ('FW: Mt. Jesus Condensate', 'john.buchanan@enron.com', 'lynn.blair@enron.com'), ('FW: Mt. Jesus Condensate', 'steven.january@enron.com', 'lynn.blair@enron.com'), ('FW: Mt. Jesus Condensate', 'gary.spraggins@enron.com', 'lynn.blair@enron.com'), ('Hello Julia and Dave', 'juliawhite65@hotmail.com', 'lynn.blair@enron.com'), ('Re: FW: Concerns', 'rick.dietz@enron.com', 'lynn.blair@enron.com'), ('2- SURVEY/INFORMATION EMAIL 6-27-01', 'ava.garcia@enron.com', 'lynn.blair@enron.com'), ('2- SURVEY/INFORMATION EMAIL 6-27-01', 'kelly.strader@enron.com', 'lynn.blair@enron.com'), ('Maintenance Notes on El Paso, ANR, NOVA, and NGPL', 'joe.linhart@enron.com', 'lynn.blair@enron.com'), ('Maintenance Notes on El Paso, ANR, NOVA, and NGPL', 'john.buchanan@enron.com', 'lynn.blair@enron.com'), ('Maintenance Notes on El Paso, ANR, NOVA, and NGPL', 'gary.spraggins@enron.com', 'lynn.blair@enron.com'), ('Maintenance Notes on El Paso, ANR, NOVA, and NGPL', 'darrell.schoolcraft@enron.com', 'lynn.blair@enron.com'), ('Maintenance Notes on El Paso, ANR, NOVA, and NGPL', 'michael.bodnar@enron.com', 'lynn.blair@enron.com'), ('RE: IDD/Park & Ride Transfer', 'michael.bodnar@enron.com', 'lynn.blair@enron.com'), ('RE: IDD/Park & Ride Transfer', 'john.buchanan@enron.com', 'lynn.blair@enron.com'), ('FW: Oneok Bushton- An Additional Delay in Decision', 'rick.dietz@enron.com', 'lynn.blair@enron.com'), ('FW: Oneok Bushton- An Additional Delay in Decision', 'terry.kowalke@enron.com', 'lynn.blair@enron.com'), ('FW: Oneok Bushton- An Additional Delay in Decision', 'john.buchanan@enron.com', 'lynn.blair@enron.com'), ('FW: Oneok Bushton- An Additional Delay in Decision', 'larry.berger@enron.com', 'lynn.blair@enron.com'), ('FW: Oneok Bushton- An Additional Delay in Decision', 'raetta.zadow@enron.com', 'lynn.blair@enron.com'), ('RE: UPS Review', 'ava.garcia@enron.com', 'lynn.blair@enron.com'), ('Re: Western Gas Resources', 'randy.janzen@enron.com', 'lynn.blair@enron.com'), ('Re: Outlook 2000 Training', 'ava.garcia@enron.com', 'lynn.blair@enron.com'), ('Re: Western Gas Resources', 'randy.janzen@enron.com', 'lynn.blair@enron.com'), ('RE: Timely Process Extension', 'toby.kuehl@enron.com', 'lynn.blair@enron.com'), ('Re: Just Checking...', 'sharon.brown@enron.com', 'lynn.blair@enron.com'), ('FW: Monthly Acctg Meeting', 'ava.garcia@enron.com', 'lynn.blair@enron.com'), ('FW: How to use UPS for shipping on the internet', 'ava.garcia@enron.com', 'lynn.blair@enron.com'), ('Move', 'donna.scott@enron.com', 'lynn.blair@enron.com'), ('Move', 'sheila.nacey@enron.com', 'lynn.blair@enron.com'), ('Oneok Bushton- An Additional Delay in Decision', 'shelley.corman@enron.com', 'lynn.blair@enron.com'), ('RE: TMS Small Talk upgrade testing', 'terry.kowalke@enron.com', 'lynn.blair@enron.com'), ('Re: question about TW operational capacity', 'robinhold@enron.com', 'lynn.blair@enron.com'), ('Re: question about TW operational capacity', 'brobinhold@ftenergy.com', 'lynn.blair@enron.com'), (\"Re: Wednesday's meeting on Tropical Storm Allison\", 'mary.draemer@enron.com', 'lynn.blair@enron.com'), ('Action Requested: Invoice Requires Coding/Issue Resolution/Approval\\n 01790100046227', 'ava.garcia@enron.com', 'lynn.blair@enron.com'), ('Action Requested: Invoice Requires Coding/Issue Resolution/Approval\\n 01790100050371', 'ava.garcia@enron.com', 'lynn.blair@enron.com'), ('Customer Scheduler List Needed', 'terry.kowalke@enron.com', 'lynn.blair@enron.com'), ('SoCalGas Capacity Policy', 'terry.kowalke@enron.com', 'lynn.blair@enron.com'), ('SoCalGas Capacity Policy', 'beverly.miller@enron.com', 'lynn.blair@enron.com'), ('SoCalGas Capacity Policy', 'albert.hernandez@enron.com', 'lynn.blair@enron.com'), ('SoCalGas Capacity Policy', 'cynthia.rivers@enron.com', 'lynn.blair@enron.com'), ('SoCalGas Capacity Policy', 'linda.ward@enron.com', 'lynn.blair@enron.com'), ('SoCalGas Capacity Policy', 'amy.mulligan@enron.com', 'lynn.blair@enron.com'), ('SoCalGas Capacity Policy', 'tracy.minter@enron.com', 'lynn.blair@enron.com'), ('SoCalGas Capacity Policy', 'christine.mcevoy@enron.com', 'lynn.blair@enron.com'), ('FW: How to use UPS for shipping on the internet', 'ava.garcia@enron.com', 'lynn.blair@enron.com'), ('Re: FW: Assistance for Flood Relief Victims', 'ricki.winters@enron.com', 'lynn.blair@enron.com'), ('Re: STRANGERS GAS SHIPPERS AND ESTIMATED VOLUMES (6/98 thru 6/01)', 'shelley.corman@enron.com', 'lynn.blair@enron.com'), ('Re: Revised PopUp Instructions', 'terry.kowalke@enron.com', 'lynn.blair@enron.com'), ('Re: Update NNG Doc System by Tuesday, June 19th', 'larry.berger@enron.com', 'lynn.blair@enron.com'), ('Re: FW: Storage allocations', 'shelley.corman@enron.com', 'lynn.blair@enron.com'), ('Re: FW: Storage allocations', 'brad.holmes@enron.com', 'lynn.blair@enron.com'), ('Re: FW: Storage allocations', 'rick.dietz@enron.com', 'lynn.blair@enron.com'), ('Re: FW: Storage allocations', 'sheila.nacey@enron.com', 'lynn.blair@enron.com'), ('Re: Post Mortem on Tropical Storm Allison', 'ava.garcia@enron.com', 'lynn.blair@enron.com'), ('Transwestern Invoicing', 'lynn.blair@enron.com', 'lynn.blair@enron.com'), ('Re: Compressor Fuel Consumed in Colorado', 'richard.hanagriff@enron.com', 'lynn.blair@enron.com'), ('RE: Modification to the new daily SCADA Report', 'michael.bodnar@enron.com', 'lynn.blair@enron.com'), ('RE: Modification to the new daily SCADA Report', 'john.buchanan@enron.com', 'lynn.blair@enron.com'), ('RE: Modification to the new daily SCADA Report', 'terry.kowalke@enron.com', 'lynn.blair@enron.com'), ('Re: FW: Storage allocations', 'lynn.blair@enron.com', 'lynn.blair@enron.com'), ('Customer Scheduler List Needed', 'ava.garcia@enron.com', 'lynn.blair@enron.com'), ('Customer Scheduler List Needed', 'john.buchanan@enron.com', 'lynn.blair@enron.com')]\n"
     ]
    }
   ],
   "source": [
    "print(email_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com', 'lynn.blair@enron.com']\n"
     ]
    }
   ],
   "source": [
    "print(from_email_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['larry.berger@enron.com', 'raetta.zadow@enron.com', 'john.buchanan@enron.com', 'lynn.blair@enron.com', 'mike.bryant@enron.com', 'terry.kowalke@enron.com', 'jean.blair@enron.com', 'james.carr@enron.com', 'jodie.floyd@enron.com', 'katherine.perry@enron.com', 'shirley.walden@enron.com', 'nancy.callans@enron.com', 'kathy.washington@enron.com', 'diana.porter@enron.com', 'jerry.wilkens@enron.com', 'randy.bryan@enron.com', 'sherry.forbish@enron.com', 'joe.linhart@enron.com', 'kathy.sturr@enron.com', 'chris.greaney@enron.com', 'janet.mcdaniel@enron.com', 'robert.benningfield@enron.com', 'tangie.dykes@enron.com', 'debra.scurlock@enron.com', 'randy.janzen@enron.com', 'jean.adams@enron.com', 'harry.woodson@enron.com', 'scott.hibbard@enron.com', 'beverly.miller@enron.com', 'albert.hernandez@enron.com', 'cynthia.rivers@enron.com', 'linda.ward@enron.com', 'amy.mulligan@enron.com', 'tracy.minter@enron.com', 'christine.mcevoy@enron.com', 'raetta.zadow@enron.com', 'larry.berger@enron.com', 'harry.woodson@enron.com', 'john.buchanan@enron.com', 'steven.january@enron.com', 'gary.spraggins@enron.com', 'juliawhite65@hotmail.com', 'rick.dietz@enron.com', 'ava.garcia@enron.com', 'kelly.strader@enron.com', 'joe.linhart@enron.com', 'john.buchanan@enron.com', 'gary.spraggins@enron.com', 'darrell.schoolcraft@enron.com', 'michael.bodnar@enron.com', 'michael.bodnar@enron.com', 'john.buchanan@enron.com', 'rick.dietz@enron.com', 'terry.kowalke@enron.com', 'john.buchanan@enron.com', 'larry.berger@enron.com', 'raetta.zadow@enron.com', 'ava.garcia@enron.com', 'randy.janzen@enron.com', 'ava.garcia@enron.com', 'randy.janzen@enron.com', 'toby.kuehl@enron.com', 'sharon.brown@enron.com', 'ava.garcia@enron.com', 'ava.garcia@enron.com', 'donna.scott@enron.com', 'sheila.nacey@enron.com', 'shelley.corman@enron.com', 'terry.kowalke@enron.com', 'robinhold@enron.com', 'brobinhold@ftenergy.com', 'mary.draemer@enron.com', 'ava.garcia@enron.com', 'ava.garcia@enron.com', 'terry.kowalke@enron.com', 'terry.kowalke@enron.com', 'beverly.miller@enron.com', 'albert.hernandez@enron.com', 'cynthia.rivers@enron.com', 'linda.ward@enron.com', 'amy.mulligan@enron.com', 'tracy.minter@enron.com', 'christine.mcevoy@enron.com', 'ava.garcia@enron.com', 'ricki.winters@enron.com', 'shelley.corman@enron.com', 'terry.kowalke@enron.com', 'larry.berger@enron.com', 'shelley.corman@enron.com', 'brad.holmes@enron.com', 'rick.dietz@enron.com', 'sheila.nacey@enron.com', 'ava.garcia@enron.com', 'lynn.blair@enron.com', 'richard.hanagriff@enron.com', 'michael.bodnar@enron.com', 'john.buchanan@enron.com', 'terry.kowalke@enron.com', 'lynn.blair@enron.com', 'ava.garcia@enron.com', 'john.buchanan@enron.com']\n"
     ]
    }
   ],
   "source": [
    "print(to_email_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(email_subject,['Email Subject','To','From'])\n",
    "from pyspark.sql.functions import monotonically_increasing_id \n",
    "df = df.select(\"*\").withColumn(\"id\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+---+\n",
      "|       Email Subject|                  To|                From| id|\n",
      "+--------------------+--------------------+--------------------+---+\n",
      "|FYI: Flowers sent...|larry.berger@enro...|lynn.blair@enron.com|  0|\n",
      "|FYI: Flowers sent...|raetta.zadow@enro...|lynn.blair@enron.com|  1|\n",
      "|FYI: Flowers sent...|john.buchanan@enr...|lynn.blair@enron.com|  2|\n",
      "|FYI: Flowers sent...|lynn.blair@enron.com|lynn.blair@enron.com|  3|\n",
      "|FYI: Flowers sent...|mike.bryant@enron...|lynn.blair@enron.com|  4|\n",
      "|FYI: Flowers sent...|terry.kowalke@enr...|lynn.blair@enron.com|  5|\n",
      "|FYI: Flowers sent...|jean.blair@enron.com|lynn.blair@enron.com|  6|\n",
      "|FYI: Flowers sent...|james.carr@enron.com|lynn.blair@enron.com|  7|\n",
      "|FYI: Flowers sent...|jodie.floyd@enron...|lynn.blair@enron.com|  8|\n",
      "|FYI: Flowers sent...|katherine.perry@e...|lynn.blair@enron.com|  9|\n",
      "|FYI: Flowers sent...|shirley.walden@en...|lynn.blair@enron.com| 10|\n",
      "|FYI: Flowers sent...|nancy.callans@enr...|lynn.blair@enron.com| 11|\n",
      "|FYI: Flowers sent...|kathy.washington@...|lynn.blair@enron.com| 12|\n",
      "|FYI: Flowers sent...|diana.porter@enro...|lynn.blair@enron.com| 13|\n",
      "|FYI: Flowers sent...|jerry.wilkens@enr...|lynn.blair@enron.com| 14|\n",
      "|FYI: Flowers sent...|randy.bryan@enron...|lynn.blair@enron.com| 15|\n",
      "|FYI: Flowers sent...|sherry.forbish@en...|lynn.blair@enron.com| 16|\n",
      "|FYI: Flowers sent...|joe.linhart@enron...|lynn.blair@enron.com| 17|\n",
      "|FYI: Flowers sent...|kathy.sturr@enron...|lynn.blair@enron.com| 18|\n",
      "|FYI: Flowers sent...|chris.greaney@enr...|lynn.blair@enron.com| 19|\n",
      "+--------------------+--------------------+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " To email address: \n",
      "\n",
      "[('ava.garcia@enron.com', 10), ('john.buchanan@enron.com', 7), ('terry.kowalke@enron.com', 7), ('larry.berger@enron.com', 4), ('raetta.zadow@enron.com', 3), ('lynn.blair@enron.com', 3), ('randy.janzen@enron.com', 3), ('rick.dietz@enron.com', 3), ('michael.bodnar@enron.com', 3), ('shelley.corman@enron.com', 3)]\n"
     ]
    }
   ],
   "source": [
    "f= FreqDist()\n",
    "print(\"\\n To email address: \\n\")\n",
    "for word in to_email_list:\n",
    "    f[word] += 1\n",
    "to_top_10 = f.most_common(10)\n",
    "to_least_10 = f.most_common()[-10:]\n",
    "print(to_top_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('darrell.schoolcraft@enron.com', 1), ('toby.kuehl@enron.com', 1), ('sharon.brown@enron.com', 1), ('donna.scott@enron.com', 1), ('robinhold@enron.com', 1), ('brobinhold@ftenergy.com', 1), ('mary.draemer@enron.com', 1), ('ricki.winters@enron.com', 1), ('brad.holmes@enron.com', 1), ('richard.hanagriff@enron.com', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(to_least_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+---+--------------------+\n",
      "|       Email Subject|                  To|                From| id| Email Subject Words|\n",
      "+--------------------+--------------------+--------------------+---+--------------------+\n",
      "|FYI: Flowers sent...|larry.berger@enro...|lynn.blair@enron.com|  0|[fyi:, flowers, s...|\n",
      "+--------------------+--------------------+--------------------+---+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer().setInputCol(\"Email Subject\").setOutputCol(\"Email Subject Words\")\n",
    "transformed = tokenizer.transform(df)\n",
    "transformed.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = StopWordsRemover().getStopWords() + [\"-\",\"_\"]\n",
    "remover = StopWordsRemover().setStopWords(stopwords).setInputCol(\"Email Subject Words\").setOutputCol(\"Filtered\")\n",
    "cleaned = remover.transform(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+---+--------------------+--------------------+\n",
      "|       Email Subject|                  To|                From| id| Email Subject Words|            Filtered|\n",
      "+--------------------+--------------------+--------------------+---+--------------------+--------------------+\n",
      "|FYI: Flowers sent...|larry.berger@enro...|lynn.blair@enron.com|  0|[fyi:, flowers, s...|[fyi:, flowers, s...|\n",
      "|FYI: Flowers sent...|raetta.zadow@enro...|lynn.blair@enron.com|  1|[fyi:, flowers, s...|[fyi:, flowers, s...|\n",
      "|FYI: Flowers sent...|john.buchanan@enr...|lynn.blair@enron.com|  2|[fyi:, flowers, s...|[fyi:, flowers, s...|\n",
      "|FYI: Flowers sent...|lynn.blair@enron.com|lynn.blair@enron.com|  3|[fyi:, flowers, s...|[fyi:, flowers, s...|\n",
      "|FYI: Flowers sent...|mike.bryant@enron...|lynn.blair@enron.com|  4|[fyi:, flowers, s...|[fyi:, flowers, s...|\n",
      "|FYI: Flowers sent...|terry.kowalke@enr...|lynn.blair@enron.com|  5|[fyi:, flowers, s...|[fyi:, flowers, s...|\n",
      "|FYI: Flowers sent...|jean.blair@enron.com|lynn.blair@enron.com|  6|[fyi:, flowers, s...|[fyi:, flowers, s...|\n",
      "|FYI: Flowers sent...|james.carr@enron.com|lynn.blair@enron.com|  7|[fyi:, flowers, s...|[fyi:, flowers, s...|\n",
      "|FYI: Flowers sent...|jodie.floyd@enron...|lynn.blair@enron.com|  8|[fyi:, flowers, s...|[fyi:, flowers, s...|\n",
      "|FYI: Flowers sent...|katherine.perry@e...|lynn.blair@enron.com|  9|[fyi:, flowers, s...|[fyi:, flowers, s...|\n",
      "|FYI: Flowers sent...|shirley.walden@en...|lynn.blair@enron.com| 10|[fyi:, flowers, s...|[fyi:, flowers, s...|\n",
      "|FYI: Flowers sent...|nancy.callans@enr...|lynn.blair@enron.com| 11|[fyi:, flowers, s...|[fyi:, flowers, s...|\n",
      "|FYI: Flowers sent...|kathy.washington@...|lynn.blair@enron.com| 12|[fyi:, flowers, s...|[fyi:, flowers, s...|\n",
      "|FYI: Flowers sent...|diana.porter@enro...|lynn.blair@enron.com| 13|[fyi:, flowers, s...|[fyi:, flowers, s...|\n",
      "|FYI: Flowers sent...|jerry.wilkens@enr...|lynn.blair@enron.com| 14|[fyi:, flowers, s...|[fyi:, flowers, s...|\n",
      "|FYI: Flowers sent...|randy.bryan@enron...|lynn.blair@enron.com| 15|[fyi:, flowers, s...|[fyi:, flowers, s...|\n",
      "|FYI: Flowers sent...|sherry.forbish@en...|lynn.blair@enron.com| 16|[fyi:, flowers, s...|[fyi:, flowers, s...|\n",
      "|FYI: Flowers sent...|joe.linhart@enron...|lynn.blair@enron.com| 17|[fyi:, flowers, s...|[fyi:, flowers, s...|\n",
      "|FYI: Flowers sent...|kathy.sturr@enron...|lynn.blair@enron.com| 18|[fyi:, flowers, s...|[fyi:, flowers, s...|\n",
      "|FYI: Flowers sent...|chris.greaney@enr...|lynn.blair@enron.com| 19|[fyi:, flowers, s...|[fyi:, flowers, s...|\n",
      "+--------------------+--------------------+--------------------+---+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Maintenance', 'Notes', 'on', 'El', 'Paso', ',', 'ANR', ',', 'NOVA', ',', 'and', 'NGPL'], ['RE', ':', 'Timely', 'Process', 'Extension'], ['Re', ':', 'Just', 'Checking', '...'], ['Move'], ['Re', ':', 'question', 'about', 'TW', 'operational', 'capacity'], ['Re', ':', 'question', 'about', 'TW', 'operational', 'capacity'], ['Re', ':', 'Wednesday', \"'s\", 'meeting', 'on', 'Tropical', 'Storm', 'Allison'], ['Re', ':', 'FW', ':', 'Assistance', 'for', 'Flood', 'Relief', 'Victims'], ['Re', ':', 'FW', ':', 'Storage', 'allocations'], ['Re', ':', 'Compressor', 'Fuel', 'Consumed', 'in', 'Colorado']]\n"
     ]
    }
   ],
   "source": [
    "print(words_subject_least)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_words = FreqDist()\n",
    "for e in words_subject:\n",
    "    for ea in e:\n",
    "        f_words[ea] += 1\n",
    "    print(f_words.most_common(20))##for each email checking most common 20 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 3), ('Maintenance', 1), ('Notes', 1), ('on', 1), ('El', 1), ('Paso', 1), ('ANR', 1), ('NOVA', 1), ('and', 1), ('NGPL', 1)]\n",
      "[(',', 3), ('Maintenance', 1), ('Notes', 1), ('on', 1), ('El', 1), ('Paso', 1), ('ANR', 1), ('NOVA', 1), ('and', 1), ('NGPL', 1), ('RE', 1), (':', 1), ('Timely', 1), ('Process', 1), ('Extension', 1)]\n",
      "[(',', 3), (':', 2), ('Maintenance', 1), ('Notes', 1), ('on', 1), ('El', 1), ('Paso', 1), ('ANR', 1), ('NOVA', 1), ('and', 1), ('NGPL', 1), ('RE', 1), ('Timely', 1), ('Process', 1), ('Extension', 1), ('Re', 1), ('Just', 1), ('Checking', 1), ('...', 1)]\n",
      "[(',', 3), (':', 2), ('Maintenance', 1), ('Notes', 1), ('on', 1), ('El', 1), ('Paso', 1), ('ANR', 1), ('NOVA', 1), ('and', 1), ('NGPL', 1), ('RE', 1), ('Timely', 1), ('Process', 1), ('Extension', 1), ('Re', 1), ('Just', 1), ('Checking', 1), ('...', 1), ('Move', 1)]\n",
      "[('on', 1), ('El', 1), ('Paso', 1), ('ANR', 1), ('NOVA', 1), ('and', 1), ('NGPL', 1), ('RE', 1), ('Timely', 1), ('Process', 1), ('Extension', 1), ('Just', 1), ('Checking', 1), ('...', 1), ('Move', 1), ('question', 1), ('about', 1), ('TW', 1), ('operational', 1), ('capacity', 1)]\n",
      "[('TW', 2), ('operational', 2), ('capacity', 2), ('Maintenance', 1), ('Notes', 1), ('on', 1), ('El', 1), ('Paso', 1), ('ANR', 1), ('NOVA', 1), ('and', 1), ('NGPL', 1), ('RE', 1), ('Timely', 1), ('Process', 1), ('Extension', 1), ('Just', 1), ('Checking', 1), ('...', 1), ('Move', 1)]\n",
      "[('El', 1), ('Paso', 1), ('ANR', 1), ('NOVA', 1), ('and', 1), ('NGPL', 1), ('RE', 1), ('Timely', 1), ('Process', 1), ('Extension', 1), ('Just', 1), ('Checking', 1), ('...', 1), ('Move', 1), ('Wednesday', 1), (\"'s\", 1), ('meeting', 1), ('Tropical', 1), ('Storm', 1), ('Allison', 1)]\n",
      "[('RE', 1), ('Timely', 1), ('Process', 1), ('Extension', 1), ('Just', 1), ('Checking', 1), ('...', 1), ('Move', 1), ('Wednesday', 1), (\"'s\", 1), ('meeting', 1), ('Tropical', 1), ('Storm', 1), ('Allison', 1), ('FW', 1), ('Assistance', 1), ('for', 1), ('Flood', 1), ('Relief', 1), ('Victims', 1)]\n",
      "[('Timely', 1), ('Process', 1), ('Extension', 1), ('Just', 1), ('Checking', 1), ('...', 1), ('Move', 1), ('Wednesday', 1), (\"'s\", 1), ('meeting', 1), ('Tropical', 1), ('Storm', 1), ('Allison', 1), ('Assistance', 1), ('for', 1), ('Flood', 1), ('Relief', 1), ('Victims', 1), ('Storage', 1), ('allocations', 1)]\n",
      "[('...', 1), ('Move', 1), ('Wednesday', 1), (\"'s\", 1), ('meeting', 1), ('Tropical', 1), ('Storm', 1), ('Allison', 1), ('Assistance', 1), ('for', 1), ('Flood', 1), ('Relief', 1), ('Victims', 1), ('Storage', 1), ('allocations', 1), ('Compressor', 1), ('Fuel', 1), ('Consumed', 1), ('in', 1), ('Colorado', 1)]\n"
     ]
    }
   ],
   "source": [
    "f_words_least = FreqDist()\n",
    "for e in words_subject_least:\n",
    "    for ea in e:\n",
    "        f_words_least[ea] += 1\n",
    "    print(f_words_least.most_common()[-20:])##for each email checking most common 20 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(f_words.most_common(20))## In total for all emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('...', 1), ('Move', 1), ('Wednesday', 1), (\"'s\", 1), ('meeting', 1), ('Tropical', 1), ('Storm', 1), ('Allison', 1), ('Assistance', 1), ('for', 1), ('Flood', 1), ('Relief', 1), ('Victims', 1), ('Storage', 1), ('allocations', 1), ('Compressor', 1), ('Fuel', 1), ('Consumed', 1), ('in', 1), ('Colorado', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(f_words_least.most_common()[-20:])## In total for all emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|           col|count|\n",
      "+--------------+-----+\n",
      "|       flowers|   35|\n",
      "|         terra|    2|\n",
      "|     extension|    1|\n",
      "|         paso,|    5|\n",
      "|           re:|   27|\n",
      "|     strangers|    1|\n",
      "|          anr,|    5|\n",
      "|      customer|    3|\n",
      "|01790100046227|    1|\n",
      "|      tuesday,|    1|\n",
      "|      tropical|    2|\n",
      "|          fyi:|   35|\n",
      "|  instructions|    1|\n",
      "|         galen|   35|\n",
      "|       process|    1|\n",
      "|    compressor|    1|\n",
      "|            by|    1|\n",
      "|           new|    3|\n",
      "|01790100050371|    1|\n",
      "|   wednesday's|    1|\n",
      "+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as f\n",
    "counts = cleaned.select(f.explode('Email Subject Words').alias('col')).groupBy('col').count()\n",
    "\n",
    "counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|     col|count|\n",
      "+--------+-----+\n",
      "|      to|   40|\n",
      "|   galen|   35|\n",
      "| flowers|   35|\n",
      "|    fyi:|   35|\n",
      "|    sent|   35|\n",
      "|     re:|   27|\n",
      "|     fw:|   19|\n",
      "|capacity|   10|\n",
      "|      on|    9|\n",
      "|socalgas|    8|\n",
      "+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "counts.sort(desc(\"count\")).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+---+--------------------+--------------------+--------------------+\n",
      "|       Email Subject|                  To|                From| id| Email Subject Words|            Filtered|            features|\n",
      "+--------------------+--------------------+--------------------+---+--------------------+--------------------+--------------------+\n",
      "|FYI: Flowers sent...|larry.berger@enro...|lynn.blair@enron.com|  0|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|\n",
      "|FYI: Flowers sent...|raetta.zadow@enro...|lynn.blair@enron.com|  1|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|\n",
      "|FYI: Flowers sent...|john.buchanan@enr...|lynn.blair@enron.com|  2|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|\n",
      "|FYI: Flowers sent...|lynn.blair@enron.com|lynn.blair@enron.com|  3|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|\n",
      "|FYI: Flowers sent...|mike.bryant@enron...|lynn.blair@enron.com|  4|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|\n",
      "|FYI: Flowers sent...|terry.kowalke@enr...|lynn.blair@enron.com|  5|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|\n",
      "|FYI: Flowers sent...|jean.blair@enron.com|lynn.blair@enron.com|  6|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|\n",
      "|FYI: Flowers sent...|james.carr@enron.com|lynn.blair@enron.com|  7|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|\n",
      "|FYI: Flowers sent...|jodie.floyd@enron...|lynn.blair@enron.com|  8|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|\n",
      "|FYI: Flowers sent...|katherine.perry@e...|lynn.blair@enron.com|  9|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|\n",
      "|FYI: Flowers sent...|shirley.walden@en...|lynn.blair@enron.com| 10|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|\n",
      "|FYI: Flowers sent...|nancy.callans@enr...|lynn.blair@enron.com| 11|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|\n",
      "|FYI: Flowers sent...|kathy.washington@...|lynn.blair@enron.com| 12|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|\n",
      "|FYI: Flowers sent...|diana.porter@enro...|lynn.blair@enron.com| 13|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|\n",
      "|FYI: Flowers sent...|jerry.wilkens@enr...|lynn.blair@enron.com| 14|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|\n",
      "|FYI: Flowers sent...|randy.bryan@enron...|lynn.blair@enron.com| 15|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|\n",
      "|FYI: Flowers sent...|sherry.forbish@en...|lynn.blair@enron.com| 16|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|\n",
      "|FYI: Flowers sent...|joe.linhart@enron...|lynn.blair@enron.com| 17|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|\n",
      "|FYI: Flowers sent...|kathy.sturr@enron...|lynn.blair@enron.com| 18|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|\n",
      "|FYI: Flowers sent...|chris.greaney@enr...|lynn.blair@enron.com| 19|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|\n",
      "+--------------------+--------------------+--------------------+---+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate features\n",
    "from pyspark.ml.feature import CountVectorizer, CountVectorizerModel\n",
    "cvmodel = CountVectorizer().setInputCol(\"Filtered\").setOutputCol(\"features\").fit(cleaned)\n",
    "featured = cvmodel.transform(cleaned)\n",
    "featured.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+---+--------------------+--------------------+--------------------+----------+\n",
      "|       Email Subject|                  To|                From| id| Email Subject Words|            Filtered|            features|prediction|\n",
      "+--------------------+--------------------+--------------------+---+--------------------+--------------------+--------------------+----------+\n",
      "|FYI: Flowers sent...|larry.berger@enro...|lynn.blair@enron.com|  0|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|\n",
      "|FYI: Flowers sent...|raetta.zadow@enro...|lynn.blair@enron.com|  1|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|\n",
      "|FYI: Flowers sent...|john.buchanan@enr...|lynn.blair@enron.com|  2|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|\n",
      "|FYI: Flowers sent...|lynn.blair@enron.com|lynn.blair@enron.com|  3|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|\n",
      "|FYI: Flowers sent...|mike.bryant@enron...|lynn.blair@enron.com|  4|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|\n",
      "|FYI: Flowers sent...|terry.kowalke@enr...|lynn.blair@enron.com|  5|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|\n",
      "|FYI: Flowers sent...|jean.blair@enron.com|lynn.blair@enron.com|  6|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|\n",
      "|FYI: Flowers sent...|james.carr@enron.com|lynn.blair@enron.com|  7|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|\n",
      "|FYI: Flowers sent...|jodie.floyd@enron...|lynn.blair@enron.com|  8|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|\n",
      "|FYI: Flowers sent...|katherine.perry@e...|lynn.blair@enron.com|  9|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|\n",
      "|FYI: Flowers sent...|shirley.walden@en...|lynn.blair@enron.com| 10|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|\n",
      "|FYI: Flowers sent...|nancy.callans@enr...|lynn.blair@enron.com| 11|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|\n",
      "|FYI: Flowers sent...|kathy.washington@...|lynn.blair@enron.com| 12|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|\n",
      "|FYI: Flowers sent...|diana.porter@enro...|lynn.blair@enron.com| 13|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|\n",
      "|FYI: Flowers sent...|jerry.wilkens@enr...|lynn.blair@enron.com| 14|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|\n",
      "|FYI: Flowers sent...|randy.bryan@enron...|lynn.blair@enron.com| 15|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|\n",
      "|FYI: Flowers sent...|sherry.forbish@en...|lynn.blair@enron.com| 16|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|\n",
      "|FYI: Flowers sent...|joe.linhart@enron...|lynn.blair@enron.com| 17|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|\n",
      "|FYI: Flowers sent...|kathy.sturr@enron...|lynn.blair@enron.com| 18|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|\n",
      "|FYI: Flowers sent...|chris.greaney@enr...|lynn.blair@enron.com| 19|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|\n",
      "+--------------------+--------------------+--------------------+---+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans, LDA, LDAModel\n",
    "kmeans = KMeans(k=4, seed=1)\n",
    "model = kmeans.fit(featured.select(\"features\"))\n",
    "transformedkmeans = model.transform(featured)\n",
    "transformedkmeans.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+---+--------------------+--------------------+--------------------+----------+--------------------+\n",
      "|       Email Subject|                  To|                From| id| Email Subject Words|            Filtered|            features|prediction|   topicDistribution|\n",
      "+--------------------+--------------------+--------------------+---+--------------------+--------------------+--------------------+----------+--------------------+\n",
      "|FYI: Flowers sent...|larry.berger@enro...|lynn.blair@enron.com|  0|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|[0.04722578276167...|\n",
      "|FYI: Flowers sent...|raetta.zadow@enro...|lynn.blair@enron.com|  1|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|[0.04722578276167...|\n",
      "|FYI: Flowers sent...|john.buchanan@enr...|lynn.blair@enron.com|  2|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|[0.04722578276167...|\n",
      "|FYI: Flowers sent...|lynn.blair@enron.com|lynn.blair@enron.com|  3|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|[0.04722578276167...|\n",
      "|FYI: Flowers sent...|mike.bryant@enron...|lynn.blair@enron.com|  4|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|[0.04722578276167...|\n",
      "|FYI: Flowers sent...|terry.kowalke@enr...|lynn.blair@enron.com|  5|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|[0.04722578276167...|\n",
      "|FYI: Flowers sent...|jean.blair@enron.com|lynn.blair@enron.com|  6|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|[0.04722578276167...|\n",
      "|FYI: Flowers sent...|james.carr@enron.com|lynn.blair@enron.com|  7|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|[0.04722578276167...|\n",
      "|FYI: Flowers sent...|jodie.floyd@enron...|lynn.blair@enron.com|  8|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|[0.04722578276167...|\n",
      "|FYI: Flowers sent...|katherine.perry@e...|lynn.blair@enron.com|  9|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|[0.04722578276167...|\n",
      "|FYI: Flowers sent...|shirley.walden@en...|lynn.blair@enron.com| 10|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|[0.04722578276167...|\n",
      "|FYI: Flowers sent...|nancy.callans@enr...|lynn.blair@enron.com| 11|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|[0.04722578276167...|\n",
      "|FYI: Flowers sent...|kathy.washington@...|lynn.blair@enron.com| 12|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|[0.04722578276167...|\n",
      "|FYI: Flowers sent...|diana.porter@enro...|lynn.blair@enron.com| 13|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|[0.04722578276167...|\n",
      "|FYI: Flowers sent...|jerry.wilkens@enr...|lynn.blair@enron.com| 14|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|[0.04722578276167...|\n",
      "|FYI: Flowers sent...|randy.bryan@enron...|lynn.blair@enron.com| 15|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|[0.04722578276167...|\n",
      "|FYI: Flowers sent...|sherry.forbish@en...|lynn.blair@enron.com| 16|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|[0.04722578276167...|\n",
      "|FYI: Flowers sent...|joe.linhart@enron...|lynn.blair@enron.com| 17|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|[0.04722578276167...|\n",
      "|FYI: Flowers sent...|kathy.sturr@enron...|lynn.blair@enron.com| 18|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|[0.04722578276167...|\n",
      "|FYI: Flowers sent...|chris.greaney@enr...|lynn.blair@enron.com| 19|[fyi:, flowers, s...|[fyi:, flowers, s...|(118,[0,1,2,3],[1...|         1|[0.04722578276167...|\n",
      "+--------------------+--------------------+--------------------+---+--------------------+--------------------+--------------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda = LDA(k=4,maxIter=10)\n",
    "ldamodel = lda.fit(transformedkmeans.select('id','features'))\n",
    "transformed = ldamodel.transform(transformedkmeans)\n",
    "transformed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|   topicDistribution|\n",
      "+--------------------+\n",
      "|[0.04722578276167...|\n",
      "|[0.04722578276167...|\n",
      "|[0.04722578276167...|\n",
      "|[0.04722578276167...|\n",
      "|[0.04722578276167...|\n",
      "|[0.04722578276167...|\n",
      "|[0.04722578276167...|\n",
      "|[0.04722578276167...|\n",
      "|[0.04722578276167...|\n",
      "|[0.04722578276167...|\n",
      "|[0.04722578276167...|\n",
      "|[0.04722578276167...|\n",
      "|[0.04722578276167...|\n",
      "|[0.04722578276167...|\n",
      "|[0.04722578276167...|\n",
      "|[0.04722578276167...|\n",
      "|[0.04722578276167...|\n",
      "|[0.04722578276167...|\n",
      "|[0.04722578276167...|\n",
      "|[0.04722578276167...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics = ldamodel.describeTopics(4)\n",
    "transformedlda = ldamodel.transform(featured)\n",
    "transformedlda.select(\"topicDistribution\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.vocabSize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o3484.trainLDAModel.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 512.0 failed 1 times, most recent failure: Lost task 2.0 in stage 512.0 (TID 5092, 192.168.2.14, executor driver): net.razorvine.pickle.PickleException: expected zero arguments for construction of ClassDict (for pyspark.sql.types._create_row)\r\n\tat net.razorvine.pickle.objects.ClassDictConstructor.construct(ClassDictConstructor.java:23)\r\n\tat net.razorvine.pickle.Unpickler.load_reduce(Unpickler.java:773)\r\n\tat net.razorvine.pickle.Unpickler.dispatch(Unpickler.java:213)\r\n\tat net.razorvine.pickle.Unpickler.load(Unpickler.java:123)\r\n\tat net.razorvine.pickle.Unpickler.loads(Unpickler.java:136)\r\n\tat org.apache.spark.mllib.api.python.SerDeBase.$anonfun$pythonToJava$2(PythonMLLibAPI.scala:1354)\r\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\r\n\tat org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1804)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$count$1(RDD.scala:1227)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$count$1$adapted(RDD.scala:1227)\r\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2139)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2008)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2007)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2007)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:973)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:973)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:973)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2239)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2120)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2139)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2164)\r\n\tat org.apache.spark.rdd.RDD.count(RDD.scala:1227)\r\n\tat org.apache.spark.mllib.clustering.OnlineLDAOptimizer.initialize(LDAOptimizer.scala:413)\r\n\tat org.apache.spark.mllib.clustering.OnlineLDAOptimizer.initialize(LDAOptimizer.scala:258)\r\n\tat org.apache.spark.mllib.clustering.LDA.run(LDA.scala:325)\r\n\tat org.apache.spark.mllib.api.python.PythonMLLibAPI.trainLDAModel(PythonMLLibAPI.scala:547)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: net.razorvine.pickle.PickleException: expected zero arguments for construction of ClassDict (for pyspark.sql.types._create_row)\r\n\tat net.razorvine.pickle.objects.ClassDictConstructor.construct(ClassDictConstructor.java:23)\r\n\tat net.razorvine.pickle.Unpickler.load_reduce(Unpickler.java:773)\r\n\tat net.razorvine.pickle.Unpickler.dispatch(Unpickler.java:213)\r\n\tat net.razorvine.pickle.Unpickler.load(Unpickler.java:123)\r\n\tat net.razorvine.pickle.Unpickler.loads(Unpickler.java:136)\r\n\tat org.apache.spark.mllib.api.python.SerDeBase.$anonfun$pythonToJava$2(PythonMLLibAPI.scala:1354)\r\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\r\n\tat org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1804)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$count$1(RDD.scala:1227)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$count$1$adapted(RDD.scala:1227)\r\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2139)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-247-34f04946092a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Cluster the documents into three topics using LDA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mldaModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLDA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxIterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'online'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mtopics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mldaModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopicsMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mvocabArray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\mllib\\clustering.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(cls, rdd, k, maxIterations, docConcentration, topicConcentration, seed, checkpointInterval, optimizer)\u001b[0m\n\u001b[0;32m   1032\u001b[0m         model = callMLlibFunc(\"trainLDAModel\", rdd, k, maxIterations,\n\u001b[0;32m   1033\u001b[0m                               \u001b[0mdocConcentration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopicConcentration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1034\u001b[1;33m                               checkpointInterval, optimizer)\n\u001b[0m\u001b[0;32m   1035\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mLDAModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\mllib\\common.py\u001b[0m in \u001b[0;36mcallMLlibFunc\u001b[1;34m(name, *args)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[0mapi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonMLLibAPI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcallJavaFunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\mllib\\common.py\u001b[0m in \u001b[0;36mcallJavaFunc\u001b[1;34m(sc, func, *args)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;34m\"\"\" Call Java Function \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_java2py\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1305\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o3484.trainLDAModel.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 512.0 failed 1 times, most recent failure: Lost task 2.0 in stage 512.0 (TID 5092, 192.168.2.14, executor driver): net.razorvine.pickle.PickleException: expected zero arguments for construction of ClassDict (for pyspark.sql.types._create_row)\r\n\tat net.razorvine.pickle.objects.ClassDictConstructor.construct(ClassDictConstructor.java:23)\r\n\tat net.razorvine.pickle.Unpickler.load_reduce(Unpickler.java:773)\r\n\tat net.razorvine.pickle.Unpickler.dispatch(Unpickler.java:213)\r\n\tat net.razorvine.pickle.Unpickler.load(Unpickler.java:123)\r\n\tat net.razorvine.pickle.Unpickler.loads(Unpickler.java:136)\r\n\tat org.apache.spark.mllib.api.python.SerDeBase.$anonfun$pythonToJava$2(PythonMLLibAPI.scala:1354)\r\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\r\n\tat org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1804)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$count$1(RDD.scala:1227)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$count$1$adapted(RDD.scala:1227)\r\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2139)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2008)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2007)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2007)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:973)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:973)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:973)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2239)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2120)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2139)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2164)\r\n\tat org.apache.spark.rdd.RDD.count(RDD.scala:1227)\r\n\tat org.apache.spark.mllib.clustering.OnlineLDAOptimizer.initialize(LDAOptimizer.scala:413)\r\n\tat org.apache.spark.mllib.clustering.OnlineLDAOptimizer.initialize(LDAOptimizer.scala:258)\r\n\tat org.apache.spark.mllib.clustering.LDA.run(LDA.scala:325)\r\n\tat org.apache.spark.mllib.api.python.PythonMLLibAPI.trainLDAModel(PythonMLLibAPI.scala:547)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: net.razorvine.pickle.PickleException: expected zero arguments for construction of ClassDict (for pyspark.sql.types._create_row)\r\n\tat net.razorvine.pickle.objects.ClassDictConstructor.construct(ClassDictConstructor.java:23)\r\n\tat net.razorvine.pickle.Unpickler.load_reduce(Unpickler.java:773)\r\n\tat net.razorvine.pickle.Unpickler.dispatch(Unpickler.java:213)\r\n\tat net.razorvine.pickle.Unpickler.load(Unpickler.java:123)\r\n\tat net.razorvine.pickle.Unpickler.loads(Unpickler.java:136)\r\n\tat org.apache.spark.mllib.api.python.SerDeBase.$anonfun$pythonToJava$2(PythonMLLibAPI.scala:1354)\r\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\r\n\tat org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1804)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$count$1(RDD.scala:1227)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$count$1$adapted(RDD.scala:1227)\r\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2139)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\n"
     ]
    }
   ],
   "source": [
    "corpus = transformedkmeans.select(\"id\",\"features\").rdd.zipWithIndex().map(lambda x: [x[1], x[0]]).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------------------------------------------+\n",
      "|topic|                                                     topicWords|\n",
      "+-----+---------------------------------------------------------------+\n",
      "|    0|[capacity, socalgas, policy, customer, needed, scheduler, list]|\n",
      "|    1|       [re:, instructions, allison, popup, storm, revised, ups]|\n",
      "|    2|         [sent, fyi:, flowers, galen, re:, scada, modification]|\n",
      "|    3|  [fw:, additional, decision, bushton-, delay, oneok, internet]|\n",
      "+-----+---------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "vocab = cvmodel.vocabulary\n",
    "\n",
    "def get_words(token_list):\n",
    "    return [vocab[token_id] for token_id in token_list]\n",
    "udf_to_words = F.udf(get_words, ArrayType(StringType()))\n",
    "num_top_words = 7\n",
    "topics = ldamodel.describeTopics(num_top_words).withColumn('topicWords', udf_to_words(F.col('termIndices')))\n",
    "topics.select('topic', 'topicWords').show(truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
